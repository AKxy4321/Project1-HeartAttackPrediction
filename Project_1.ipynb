{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvpeTC-cZGSs",
        "outputId": "c23dc707-cfbb-4965-e433-b2eeb5bf8379"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMR-YGUfir9O"
      },
      "source": [
        "1.Implementing Heart Attack using **classification algorithms**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTHj1mz1lAvA",
        "outputId": "b9114ef7-f8c9-4a87-bec3-b4d461fcd516"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: [1]\n",
            "Accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#DecisionTree\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset from a CSV file\n",
        "data = pd.read_csv('/content/gdrive/My Drive/Sem 3/ASE/Project 1/heart.csv')\n",
        "\n",
        "# Define column names for the dataset\n",
        "names = [\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"target\"]\n",
        "data.columns = names\n",
        "\n",
        "# Remove rows with missing values (NaN)\n",
        "data = data.dropna()\n",
        "\n",
        "# Split the dataset into input features (X) and the target variable (y)\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Create a Decision Tree classifier with specific parameters\n",
        "classifier = DecisionTreeClassifier(criterion='entropy', random_state=0, ccp_alpha=0)\n",
        "\n",
        "# Train (fit) the Decision Tree classifier on the training data\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Define a new data point (X_marks) and predict its class\n",
        "X_marks = [[69, 0, 3, 133, 230, 1, 0, 150, 0, 2.3, 0, 0, 1]]\n",
        "prediction = classifier.predict(X_marks)\n",
        "\n",
        "# Print the predicted class for X_marks\n",
        "print(\"Predicted class:\", prediction)\n",
        "\n",
        "# Use the trained classifier to predict the classes for the test data\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy of the model on the test data\n",
        "accuracy = classifier.score(X_test, y_test)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jHITavYU4QY",
        "outputId": "842e506b-171e-44b9-f6d4-e6d5bb693228"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [1 1 0 1 0 0 0 0 0 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 0 0\n",
            " 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0\n",
            " 0 0 0 0 0 0 0 1 0 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 1 0 1 0 0 1 0 1 0 1 1\n",
            " 0 0 0 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 0 1 1 0\n",
            " 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1\n",
            " 0 1 0 1 0 0 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 0 0 0 1 1 0 1\n",
            " 1 0 1 0 0 1 1 0 0 0 1 0 1 0 1 1 1 0 1 0 0 0 1 1 0 1 0 0 1 0 1 1 1 0 0 0 0\n",
            " 1 1 1 1 1 1 0 0 1 0 1 0 0 1 0 1 0 0]\n",
            "Accuracy: 0.851985559566787\n"
          ]
        }
      ],
      "source": [
        "#NaiveBayes\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset from a CSV file\n",
        "data = pd.read_csv('/content/gdrive/My Drive/Sem 3/ASE/Project 1/heart.csv')\n",
        "\n",
        "# Define column names for the dataset\n",
        "names = [\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"target\"]\n",
        "data.columns = names\n",
        "\n",
        "# Remove rows with missing values (NaN)\n",
        "data = data.dropna()\n",
        "\n",
        "# Split the dataset into input features (X) and the target variable (y)\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target']\n",
        "\n",
        "# Split the data into training and testing sets, using a test size of 27%\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.27, random_state=0)\n",
        "\n",
        "# Create a Gaussian Naive Bayes classifier\n",
        "classifier = GaussianNB()\n",
        "\n",
        "# Train (fit) the Naive Bayes classifier on the training data\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Use the trained classifier to predict the classes for the test data\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Print the predicted classes\n",
        "print(\"Predictions:\", y_pred)\n",
        "\n",
        "# Calculate and print the accuracy of the model on the test data\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFeMDcBba4GQ",
        "outputId": "be1fcce8-9512-4c3c-fb8b-ac9254de76a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.958974358974359\n"
          ]
        }
      ],
      "source": [
        "#KNN\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset from a CSV file\n",
        "data = pd.read_csv('/content/gdrive/My Drive/Sem 3/ASE/Project 1/heart.csv')\n",
        "\n",
        "# Define column names for the dataset\n",
        "names = [\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"target\"]\n",
        "data.columns = names\n",
        "\n",
        "# Remove rows with missing values (NaN)\n",
        "data = data.dropna()\n",
        "\n",
        "# Split the dataset into input features (X) and the target variable (y)\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target']\n",
        "\n",
        "# Split the data into training and testing sets, using a test size of 19%\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.19, random_state=0)\n",
        "\n",
        "# Define the number of nearest neighbors to consider (k)\n",
        "k = 2\n",
        "\n",
        "# Create a K-Nearest Neighbors (KNN) classifier with k neighbors\n",
        "classifier = KNeighborsClassifier(n_neighbors=k)\n",
        "\n",
        "# Train (fit) the KNN classifier on the training data\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Use the trained classifier to predict the classes for the test data\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy of the model on the test data\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zExDoYKpc_lG",
        "outputId": "aed2aec4-2aac-409a-abd0-bd8b5f08ef19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "#Random Forest\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset from a CSV file\n",
        "data = pd.read_csv('/content/gdrive/My Drive/Sem 3/ASE/Project 1/heart.csv')\n",
        "\n",
        "# Define column names for the dataset\n",
        "names = [\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"target\"]\n",
        "data.columns = names\n",
        "\n",
        "# Remove rows with missing values (NaN)\n",
        "data = data.dropna()\n",
        "\n",
        "# Split the dataset into input features (X) and the target variable (y)\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target']\n",
        "\n",
        "# Split the data into training and testing sets, using a test size of 20%\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Define the number of trees in the Random Forest (n_estimators)\n",
        "n_estimators = 100\n",
        "\n",
        "# Create a Random Forest classifier with 100 trees\n",
        "classifier = RandomForestClassifier(n_estimators=n_estimators, random_state=0)\n",
        "\n",
        "# Train (fit) the Random Forest classifier on the training data\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Use the trained classifier to predict the classes for the test data\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy of the model on the test data\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CauhGxwtdYEG",
        "outputId": "089c988a-b004-42bf-a950-a225f74983ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8682926829268293\n"
          ]
        }
      ],
      "source": [
        "#SVM\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset from a CSV file\n",
        "data = pd.read_csv('/content/gdrive/My Drive/Sem 3/ASE/Project 1/heart.csv')\n",
        "\n",
        "# Define column names for the dataset\n",
        "names = [\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"target\"]\n",
        "data.columns = names\n",
        "\n",
        "# Remove rows with missing values (NaN)\n",
        "data is data.dropna()\n",
        "\n",
        "# Split the dataset into input features (X) and the target variable (y)\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target']\n",
        "\n",
        "# Split the data into training and testing sets, using a test size of 40%\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
        "\n",
        "# Create a Support Vector Machine (SVM) classifier with a linear kernel\n",
        "classifier = SVC(kernel='linear', random_state=0)\n",
        "\n",
        "# Train (fit) the SVM classifier on the training data\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Use the trained classifier to predict the classes for the test data\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy of the model on the test data\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CarrPGY1ehN2",
        "outputId": "1d127d3b-fe14-444d-9a5a-6c5bca22c61b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8746518105849582\n"
          ]
        }
      ],
      "source": [
        "#Logistic Regression\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset from a CSV file\n",
        "data = pd.read_csv('/content/gdrive/My Drive/Sem 3/ASE/Project 1/heart.csv')\n",
        "\n",
        "# Define column names for the dataset\n",
        "names = [\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"target\"]\n",
        "data.columns = names\n",
        "\n",
        "# Remove rows with missing values (NaN)\n",
        "data = data.dropna()\n",
        "\n",
        "# Split the dataset into input features (X) and the target variable (y)\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target']\n",
        "\n",
        "# Split the data into training and testing sets, using a test size of 35%\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=0)\n",
        "\n",
        "# Create a Logistic Regression classifier with a maximum number of iterations and a random state for reproducibility\n",
        "classifier = LogisticRegression(max_iter=2000, random_state=0)\n",
        "\n",
        "# Train (fit) the Logistic Regression classifier on the training data\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Use the trained classifier to predict the classes for the test data\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy of the model on the test data\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwqnMEjPfElK"
      },
      "source": [
        "2.Implement Heart attack using **Deeping learning**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "\n",
        "# Import necessary modules\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from math import sqrt\n",
        "\n",
        "# Keras specific\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "df = pd.read_csv(\"/content/gdrive/My Drive/Sem 3/ASE/Project 1/heart.csv\")\n",
        "\n",
        "# Split the data into features and target\n",
        "x=df.drop('target',axis=1)#Delete the target column to form Features\n",
        "y=df['target']# This forms the Label\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=42)\n",
        "\n",
        "# Standardize the input features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)\n",
        "\n",
        "\n",
        "#Defining the Model\n",
        "model = Sequential()\n",
        "model.add(Dense(500, activation='relu', input_dim=13)) #Input Layer\n",
        "\n",
        "#Creating the Hidden Layers\n",
        "model.add(Dense(1000, activation='relu'))\n",
        "model.add(Dense(1000, activation='relu'))\n",
        "model.add(Dense(500, activation='relu'))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid')) #Output Layer\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(x_train,y_train, epochs=5)\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "\n",
        "#Print the accuracy\n",
        "print('Accuracy:', accuracy)\n"
      ],
      "metadata": {
        "id": "hNSQn6HYrUDG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "749f1b0e-70a7-43c9-b51b-0334c7b2c623"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "24/24 [==============================] - 3s 15ms/step - loss: 0.3763 - accuracy: 0.8151\n",
            "Epoch 2/5\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.2637 - accuracy: 0.8945\n",
            "Epoch 3/5\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.1815 - accuracy: 0.9414\n",
            "Epoch 4/5\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.1271 - accuracy: 0.9544\n",
            "Epoch 5/5\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 0.0577 - accuracy: 0.9831\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1609 - accuracy: 0.9650\n",
            "Accuracy: 0.9649805426597595\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}