{"cells":[{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tvpeTC-cZGSs","outputId":"5b5e5ec2-ffa3-4052-9ff7-81877cb10feb","executionInfo":{"status":"ok","timestamp":1697773063284,"user_tz":-330,"elapsed":6588,"user":{"displayName":"Aditya Kushal","userId":"16777237276453722362"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive',force_remount=True)"]},{"cell_type":"markdown","metadata":{"id":"NMR-YGUfir9O"},"source":["1.Implementing Heart Attack using **classification algorithms**"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hTHj1mz1lAvA","outputId":"9f052afe-3fc7-4a12-f6cb-b61dcedea956","executionInfo":{"status":"ok","timestamp":1697773237117,"user_tz":-330,"elapsed":518,"user":{"displayName":"Aditya Kushal","userId":"16777237276453722362"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted class: [1]\n","Accuracy: 1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n","  warnings.warn(\n"]}],"source":["#DecisionTree\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","# Load the dataset from a CSV file\n","data = pd.read_csv('/content/gdrive/My Drive/Sem 3/ASE/Project 1/heart.csv')\n","\n","# Define column names for the dataset\n","names = [\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"target\"]\n","data.columns = names\n","\n","# Remove rows with missing values (NaN)\n","data = data.dropna()\n","\n","# Split the dataset into input features (X) and the target variable (y)\n","X = data.drop('target', axis=1)\n","y = data['target']\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","\n","# Create a Decision Tree classifier with specific parameters\n","classifier = DecisionTreeClassifier(criterion='entropy', random_state=0, ccp_alpha=0)\n","\n","# Train (fit) the Decision Tree classifier on the training data\n","classifier.fit(X_train, y_train)\n","\n","# Define a new data point (X_marks) and predict its class\n","X_marks = [[69, 0, 3, 133, 230, 1, 0, 150, 0, 2.3, 0, 0, 1]]\n","prediction = classifier.predict(X_marks)\n","\n","# Print the predicted class for X_marks\n","print(\"Predicted class:\", prediction)\n","\n","# Use the trained classifier to predict the classes for the test data\n","y_pred = classifier.predict(X_test)\n","\n","# Calculate and print the accuracy of the model on the test data\n","accuracy = classifier.score(X_test, y_test)\n","print(\"Accuracy:\", accuracy)\n"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2jHITavYU4QY","outputId":"12b80ce8-8fa6-4b80-b117-874ddba5a3a2","executionInfo":{"status":"ok","timestamp":1697773063285,"user_tz":-330,"elapsed":14,"user":{"displayName":"Aditya Kushal","userId":"16777237276453722362"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Predictions: [1 1 0 1 0 0 0 0 0 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 0 0\n"," 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0\n"," 0 0 0 0 0 0 0 1 0 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 1 0 1 0 0 1 0 1 0 1 1\n"," 0 0 0 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 0 1 1 0\n"," 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1\n"," 0 1 0 1 0 0 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 0 0 0 1 1 0 1\n"," 1 0 1 0 0 1 1 0 0 0 1 0 1 0 1 1 1 0 1 0 0 0 1 1 0 1 0 0 1 0 1 1 1 0 0 0 0\n"," 1 1 1 1 1 1 0 0 1 0 1 0 0 1 0 1 0 0]\n","Accuracy: 0.851985559566787\n"]}],"source":["#NaiveBayes\n","\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.metrics import accuracy_score\n","\n","# Load the dataset from a CSV file\n","data = pd.read_csv('/content/gdrive/My Drive/Sem 3/ASE/Project 1/heart.csv')\n","\n","# Define column names for the dataset\n","names = [\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"target\"]\n","data.columns = names\n","\n","# Remove rows with missing values (NaN)\n","data = data.dropna()\n","\n","# Split the dataset into input features (X) and the target variable (y)\n","X = data.drop('target', axis=1)\n","y = data['target']\n","\n","# Split the data into training and testing sets, using a test size of 27%\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.27, random_state=0)\n","\n","# Create a Gaussian Naive Bayes classifier\n","classifier = GaussianNB()\n","\n","# Train (fit) the Naive Bayes classifier on the training data\n","classifier.fit(X_train, y_train)\n","\n","# Use the trained classifier to predict the classes for the test data\n","y_pred = classifier.predict(X_test)\n","\n","# Print the predicted classes\n","print(\"Predictions:\", y_pred)\n","\n","# Calculate and print the accuracy of the model on the test data\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MFeMDcBba4GQ","outputId":"cac5a61d-1480-49f6-d90b-fb1463b785cb","executionInfo":{"status":"ok","timestamp":1697773063285,"user_tz":-330,"elapsed":11,"user":{"displayName":"Aditya Kushal","userId":"16777237276453722362"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.958974358974359\n"]}],"source":["#KNN\n","\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# Load the dataset from a CSV file\n","data = pd.read_csv('/content/gdrive/My Drive/Sem 3/ASE/Project 1/heart.csv')\n","\n","# Define column names for the dataset\n","names = [\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"target\"]\n","data.columns = names\n","\n","# Remove rows with missing values (NaN)\n","data = data.dropna()\n","\n","# Split the dataset into input features (X) and the target variable (y)\n","X = data.drop('target', axis=1)\n","y = data['target']\n","\n","# Split the data into training and testing sets, using a test size of 19%\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.19, random_state=0)\n","\n","# Define the number of nearest neighbors to consider (k)\n","k = 2\n","\n","# Create a K-Nearest Neighbors (KNN) classifier with k neighbors\n","classifier = KNeighborsClassifier(n_neighbors=k)\n","\n","# Train (fit) the KNN classifier on the training data\n","classifier.fit(X_train, y_train)\n","\n","# Use the trained classifier to predict the classes for the test data\n","y_pred = classifier.predict(X_test)\n","\n","# Calculate and print the accuracy of the model on the test data\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zExDoYKpc_lG","outputId":"11112f20-be34-4da7-a9da-c215403cf01c","executionInfo":{"status":"ok","timestamp":1697773063286,"user_tz":-330,"elapsed":9,"user":{"displayName":"Aditya Kushal","userId":"16777237276453722362"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 1.0\n"]}],"source":["#Random Forest\n","\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# Load the dataset from a CSV file\n","data = pd.read_csv('/content/gdrive/My Drive/Sem 3/ASE/Project 1/heart.csv')\n","\n","# Define column names for the dataset\n","names = [\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"target\"]\n","data.columns = names\n","\n","# Remove rows with missing values (NaN)\n","data = data.dropna()\n","\n","# Split the dataset into input features (X) and the target variable (y)\n","X = data.drop('target', axis=1)\n","y = data['target']\n","\n","# Split the data into training and testing sets, using a test size of 20%\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","\n","# Define the number of trees in the Random Forest (n_estimators)\n","n_estimators = 100\n","\n","# Create a Random Forest classifier with 100 trees\n","classifier = RandomForestClassifier(n_estimators=n_estimators, random_state=0)\n","\n","# Train (fit) the Random Forest classifier on the training data\n","classifier.fit(X_train, y_train)\n","\n","# Use the trained classifier to predict the classes for the test data\n","y_pred = classifier.predict(X_test)\n","\n","# Calculate and print the accuracy of the model on the test data\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CauhGxwtdYEG","outputId":"9b4e9f59-ee16-48d5-b71b-d494b0c4b41a","executionInfo":{"status":"ok","timestamp":1697773065984,"user_tz":-330,"elapsed":2705,"user":{"displayName":"Aditya Kushal","userId":"16777237276453722362"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.8682926829268293\n"]}],"source":["#SVM\n","\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score\n","\n","# Load the dataset from a CSV file\n","data = pd.read_csv('/content/gdrive/My Drive/Sem 3/ASE/Project 1/heart.csv')\n","\n","# Define column names for the dataset\n","names = [\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"target\"]\n","data.columns = names\n","\n","# Remove rows with missing values (NaN)\n","data is data.dropna()\n","\n","# Split the dataset into input features (X) and the target variable (y)\n","X = data.drop('target', axis=1)\n","y = data['target']\n","\n","# Split the data into training and testing sets, using a test size of 40%\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n","\n","# Create a Support Vector Machine (SVM) classifier with a linear kernel\n","classifier = SVC(kernel='linear', random_state=0)\n","\n","# Train (fit) the SVM classifier on the training data\n","classifier.fit(X_train, y_train)\n","\n","# Use the trained classifier to predict the classes for the test data\n","y_pred = classifier.predict(X_test)\n","\n","# Calculate and print the accuracy of the model on the test data\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CarrPGY1ehN2","outputId":"bf8cea28-d13d-4e85-ba03-c21b1d9a0b09","executionInfo":{"status":"ok","timestamp":1697773065985,"user_tz":-330,"elapsed":11,"user":{"displayName":"Aditya Kushal","userId":"16777237276453722362"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.8746518105849582\n"]}],"source":["#Logistic Regression\n","\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","\n","# Load the dataset from a CSV file\n","data = pd.read_csv('/content/gdrive/My Drive/Sem 3/ASE/Project 1/heart.csv')\n","\n","# Define column names for the dataset\n","names = [\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"target\"]\n","data.columns = names\n","\n","# Remove rows with missing values (NaN)\n","data = data.dropna()\n","\n","# Split the dataset into input features (X) and the target variable (y)\n","X = data.drop('target', axis=1)\n","y = data['target']\n","\n","# Split the data into training and testing sets, using a test size of 35%\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=0)\n","\n","# Create a Logistic Regression classifier with a maximum number of iterations and a random state for reproducibility\n","classifier = LogisticRegression(max_iter=2000, random_state=0)\n","\n","# Train (fit) the Logistic Regression classifier on the training data\n","classifier.fit(X_train, y_train)\n","\n","# Use the trained classifier to predict the classes for the test data\n","y_pred = classifier.predict(X_test)\n","\n","# Calculate and print the accuracy of the model on the test data\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n"]},{"cell_type":"markdown","metadata":{"id":"QwqnMEjPfElK"},"source":["2.Implement Heart attack using **Deeping learning**"]},{"cell_type":"code","source":["# Import required libraries\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import sklearn\n","\n","# Import necessary modules\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","from sklearn.preprocessing import StandardScaler\n","\n","from math import sqrt\n","\n","# Keras specific\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.utils import to_categorical\n","\n","df = pd.read_csv(\"/content/gdrive/My Drive/Sem 3/ASE/Project 1/lungcancer_updated.csv\")\n","\n","# Split the data into features and target\n","x=df.drop('LUNG_CANCER',axis=1)#Delete the target column to form Features\n","y=df['LUNG_CANCER']# This forms the Label\n","\n","# Split the data into training and testing sets\n","x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=42)\n","\n","# Standardize the input features using StandardScaler\n","scaler = StandardScaler()\n","x_train = scaler.fit_transform(x_train)\n","x_test = scaler.transform(x_test)\n","\n","\n","#Defining the Model\n","model = Sequential()\n","model.add(Dense(500, activation='relu', input_dim=15)) #Input Layer\n","\n","#Creating the Hidden Layers\n","model.add(Dense(1000, activation='relu'))\n","model.add(Dense(1000, activation='relu'))\n","model.add(Dense(500, activation='relu'))\n","\n","model.add(Dense(1, activation='sigmoid')) #Output Layer\n","\n","# Compile the model\n","model.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","model.fit(x_train,y_train, epochs=100)\n","loss, accuracy = model.evaluate(x_test, y_test)\n","\n","#Print the accuracy\n","print('Accuracy:', accuracy)\n"],"metadata":{"id":"hNSQn6HYrUDG","executionInfo":{"status":"ok","timestamp":1697773808872,"user_tz":-330,"elapsed":12082,"user":{"displayName":"Aditya Kushal","userId":"16777237276453722362"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0cd11c59-fdf2-413c-aac7-eec9fc0aea37"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","8/8 [==============================] - 2s 5ms/step - loss: 0.4202 - accuracy: 0.7576\n","Epoch 2/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.2127 - accuracy: 0.9048\n","Epoch 3/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.1490 - accuracy: 0.9394\n","Epoch 4/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.1485 - accuracy: 0.9394\n","Epoch 5/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.1196 - accuracy: 0.9481\n","Epoch 6/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.1156 - accuracy: 0.9481\n","Epoch 7/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0981 - accuracy: 0.9524\n","Epoch 8/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0882 - accuracy: 0.9654\n","Epoch 9/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0786 - accuracy: 0.9654\n","Epoch 10/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0849 - accuracy: 0.9610\n","Epoch 11/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0677 - accuracy: 0.9697\n","Epoch 12/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0549 - accuracy: 0.9697\n","Epoch 13/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0482 - accuracy: 0.9740\n","Epoch 14/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0595 - accuracy: 0.9697\n","Epoch 15/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0583 - accuracy: 0.9697\n","Epoch 16/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0672 - accuracy: 0.9697\n","Epoch 17/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0524 - accuracy: 0.9784\n","Epoch 18/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0506 - accuracy: 0.9784\n","Epoch 19/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0656 - accuracy: 0.9654\n","Epoch 20/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0916 - accuracy: 0.9567\n","Epoch 21/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0791 - accuracy: 0.9697\n","Epoch 22/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0776 - accuracy: 0.9610\n","Epoch 23/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0596 - accuracy: 0.9784\n","Epoch 24/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0543 - accuracy: 0.9784\n","Epoch 25/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0429 - accuracy: 0.9827\n","Epoch 26/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0393 - accuracy: 0.9827\n","Epoch 27/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0344 - accuracy: 0.9827\n","Epoch 28/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0347 - accuracy: 0.9827\n","Epoch 29/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0338 - accuracy: 0.9784\n","Epoch 30/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0310 - accuracy: 0.9827\n","Epoch 31/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0353 - accuracy: 0.9827\n","Epoch 32/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0419 - accuracy: 0.9740\n","Epoch 33/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0365 - accuracy: 0.9784\n","Epoch 34/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0343 - accuracy: 0.9784\n","Epoch 35/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0317 - accuracy: 0.9827\n","Epoch 36/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0314 - accuracy: 0.9827\n","Epoch 37/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0294 - accuracy: 0.9827\n","Epoch 38/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0335 - accuracy: 0.9827\n","Epoch 39/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0281 - accuracy: 0.9827\n","Epoch 40/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0321 - accuracy: 0.9784\n","Epoch 41/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0284 - accuracy: 0.9827\n","Epoch 42/100\n","8/8 [==============================] - 0s 6ms/step - loss: 0.0310 - accuracy: 0.9827\n","Epoch 43/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0292 - accuracy: 0.9827\n","Epoch 44/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0289 - accuracy: 0.9827\n","Epoch 45/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0279 - accuracy: 0.9784\n","Epoch 46/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0301 - accuracy: 0.9827\n","Epoch 47/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0290 - accuracy: 0.9784\n","Epoch 48/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0279 - accuracy: 0.9827\n","Epoch 49/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0279 - accuracy: 0.9827\n","Epoch 50/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0285 - accuracy: 0.9827\n","Epoch 51/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0311 - accuracy: 0.9827\n","Epoch 52/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0264 - accuracy: 0.9827\n","Epoch 53/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0291 - accuracy: 0.9784\n","Epoch 54/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0284 - accuracy: 0.9827\n","Epoch 55/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0266 - accuracy: 0.9827\n","Epoch 56/100\n","8/8 [==============================] - 0s 6ms/step - loss: 0.0307 - accuracy: 0.9827\n","Epoch 57/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0268 - accuracy: 0.9827\n","Epoch 58/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0250 - accuracy: 0.9827\n","Epoch 59/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0283 - accuracy: 0.9870\n","Epoch 60/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0343 - accuracy: 0.9827\n","Epoch 61/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0346 - accuracy: 0.9784\n","Epoch 62/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0364 - accuracy: 0.9740\n","Epoch 63/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0450 - accuracy: 0.9784\n","Epoch 64/100\n","8/8 [==============================] - 0s 6ms/step - loss: 0.0844 - accuracy: 0.9740\n","Epoch 65/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0383 - accuracy: 0.9784\n","Epoch 66/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0394 - accuracy: 0.9784\n","Epoch 67/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0427 - accuracy: 0.9827\n","Epoch 68/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0402 - accuracy: 0.9784\n","Epoch 69/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0375 - accuracy: 0.9784\n","Epoch 70/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0343 - accuracy: 0.9827\n","Epoch 71/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0335 - accuracy: 0.9784\n","Epoch 72/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0319 - accuracy: 0.9827\n","Epoch 73/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0314 - accuracy: 0.9784\n","Epoch 74/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0322 - accuracy: 0.9827\n","Epoch 75/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0321 - accuracy: 0.9784\n","Epoch 76/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0290 - accuracy: 0.9827\n","Epoch 77/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0348 - accuracy: 0.9827\n","Epoch 78/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0339 - accuracy: 0.9827\n","Epoch 79/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0359 - accuracy: 0.9784\n","Epoch 80/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0339 - accuracy: 0.9827\n","Epoch 81/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0337 - accuracy: 0.9827\n","Epoch 82/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0325 - accuracy: 0.9827\n","Epoch 83/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0317 - accuracy: 0.9827\n","Epoch 84/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0318 - accuracy: 0.9827\n","Epoch 85/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0335 - accuracy: 0.9827\n","Epoch 86/100\n","8/8 [==============================] - 0s 6ms/step - loss: 0.0307 - accuracy: 0.9827\n","Epoch 87/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0314 - accuracy: 0.9827\n","Epoch 88/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0308 - accuracy: 0.9827\n","Epoch 89/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0295 - accuracy: 0.9870\n","Epoch 90/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0357 - accuracy: 0.9827\n","Epoch 91/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0318 - accuracy: 0.9870\n","Epoch 92/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0310 - accuracy: 0.9827\n","Epoch 93/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0312 - accuracy: 0.9827\n","Epoch 94/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0301 - accuracy: 0.9827\n","Epoch 95/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0296 - accuracy: 0.9827\n","Epoch 96/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0290 - accuracy: 0.9827\n","Epoch 97/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0310 - accuracy: 0.9827\n","Epoch 98/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0287 - accuracy: 0.9827\n","Epoch 99/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0293 - accuracy: 0.9827\n","Epoch 100/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0279 - accuracy: 0.9913\n","3/3 [==============================] - 0s 6ms/step - loss: 0.3899 - accuracy: 0.9615\n","Accuracy: 0.9615384340286255\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}